 Agora que eu acho que a gente está na mesma página e eu acho que deu para a gente dar uma contextualizada da importância que é você ter uma estrutura clara ali de prompt, eu quero agora chegar e ir um pouco mais para essas estruturações. Então é o seguinte, a gente tem alguns casos importantes. Quando o problema não será respondido pela IA em larga escala, não economize em tokens. essa é uma pergunta muito comum que acontece quando eu começo a desenvolver eu coloco um prompt gigante lá a primeira coisa que algumas pessoas torcem o nariz para mim, pelo meu comportamento é o seguinte e a janela de contexto? e a quantidade de tokens? não vai dar certo isso que você está fazendo e o que eu tenho percebido e novamente eu não sou o rei da verdade é que quando a gente vai trabalhar com código e desenvolvimento, se a gente economizar em tokens, e codificação é algo extremamente complexo, então se a gente não economizar, a gente tem uma chance maior de diminuir o problema. E o grande ponto é que muitas vezes você pode usar um prompt gigante para resolver um problema pequeno. Então você não vai ter problemas em janela de contexto. Coisas interessantes, por exemplo, é se você pegar um Gemini da vida com mais de um milhão de promptes, de promptes não, de janela de contexto, chega a dois milhões, se você pegar um GPT-5 da vida, ele tem, eu acho que perto de 500 mil tokens, mas ele tem algo fantástico, que é 128 mil tokens de saída em alta performance. Então, a primeira coisa que você não deve ficar preocupado é no momento que você for desenvolver software, você ficar economizando tokens. Principalmente porque hoje em dia, grande parte dos planos das IDEs e etc eles n est mais cobrando necessariamente por tokens Normalmente eles est cobrando por utilização. É óbvio que por trás dos planos eles podem estar fazendo e devem estar fazendo as contas por token. Mas não é como era antes que você passava a sua API Key e cada token contava e saía uma conta muito clara. Vou dar um exemplo para você e esse exemplo está acontecendo no momento dessa gravação, provavelmente daqui a um ano, daqui a seis meses ou alguma coisa desse tipo, isso aqui pode estar em um formato completamente diferente. Mas, por exemplo, se eu pegar uma API Key da Anthropic e colocar isso no Cloud Code, eu vou gastar uma grana absurda para passar o dia inteiro desenvolvendo. Agora, se eu assinar o plano do Cloud Code, eu acho que é Max, sei lá como é o nome do plano, custa 100 dólares por mês, Ou seja, não é um valor também tão barato. Eu hoje consigo trabalhar quase que de forma ilimitada com esse modelo, sem ter surpresas no final do mês. E além disso, em alguns momentos eu posso utilizar modelos de reasoning, sei lá, o Opus, por exemplo, que consegue inclusive ter resultados melhores, mas aí ele gasta mais ali a sua possibilidade de trabalhar com ele. mas daí vai depender da empresa o quanto você quer gastar dinheiro no seu bolso porque existem planos, sei lá, de 200 dólares por mês que você acaba utilizando ele quase de forma ilimitada. Pessoal, a minha questão aqui não é falar de dinheiro e não é falar que 100 dólares é barato, tá? 100 dólares é bastante dinheiro mas, tá? Para mim, tá? 100 dólares perto da produtividade que eu tenho por exemplo, se eu for usar o cloud assim, ele se paga muito rápido. E eu espero que ao longo do tempo, cada vez mais as empresas, elas possam fornecer ferramentas de IA inclusas no pacote E um ponto inicial que poderia acontecer e s testes que por exemplo hoje eu estou fazendo na empresa porque a gente tem desenvolvedores o seguinte Eu comecei a fazer comparação, por exemplo, do Gemini, CLI, Command Line Interface do Gemini, e com o resultado com o Cloud Code, com o GPT-5, com o uso no Codex e tudo mais. e o que eu acabei percebendo é que os resultados, por exemplo que o Gemini tem me retornado eles são muito similares ao que o Cloud, a única coisa é que o Gemini pelo menos nesse momento ele não tem tantos recursos no CLI, mas o resultado final está sendo quase que o mesmo e pelo menos nesse momento que eu estou gravando, o que acontece o Gemini ele está ali basicamente prometendo que você faça, eu acredito, mil requests por dia e 60 requests por minuto. Meu, para você conseguir fazer isso, é muita coisa, tá? É muita coisa. E essa possibilidade, ela é gratuita, pelo menos por enquanto. Então, muitas vezes, para colocar o pé na água, você não precisa gastar um centavo para trabalhar com inteligência artificial, porque, por exemplo, o Google ou o Gemini, pelo menos no momento dessa gravação, você tem um plano que você acaba não pagando nada, usando um limite absurdo. Pode ser que no futuro eles cobrem e tirem esses planos? Podem ser. Mas eu acredito que sempre vale a pena a gente manter a mente aberta e ver quais são as soluções mais baratas que conseguem resultados similares. Às vezes o resultado não é tão bom, mas é um resultado que, no final do dia, vai fazer eu economizar dinheiro ou a empresa economizar dinheiro também. Então, são coisas que eu quero que você acabe pensando, tá? Mas, para resumir, o que eu queria trazer aqui para vocês é toda vez que você for trabalhar para desenvolvimento com o IA, não economize em tokens. O que voc pode ter s estrat que v fazer com que a IA precise ler o seu codebase inteiro com 100 mil arquivos Voc consegue dar instru mais claras para que ela consiga trabalhar com branches e leafs Ou seja, eu tenho um projeto e esse projeto começa aqui. E daí ele tem uma ramificação de componentes, que são componentes que vão para cá. Lá ele tem componentes que vão para cá Então ele vai gerando quase que fosse uma árvore Esse componente se quebra para cá Legal? Esse componente se quebra para cá Bacana Esse cara aqui, ele se quebra para cá Legal? E aí no final das contas Quando eu peço para a IA resolver algum problema eu chego e falo o seguinte, olha, eu quero que você resolva os meus problemas, os meus componentes, mas eu quero que você parta a partir desse princípio, seguindo esse fluxo aqui. Todo o restante você ignora e você consegue mapear. Mas tudo isso depende muito de como você estrutura a sua aplicação. Se a sua aplicação trabalha de uma forma bem modular, os componentes estão desacoplados o suficiente, você consegue sim fazer com que a IA ela entenda o contexto desse pedaço sem ter que internalizar toda essa outra parte e nesses casos você pode, por exemplo criar documentações e instruções em cada pedaço para que ela evite sair e entrar em outra bolha de partes do seu sistema então são coisas que você pode fazer o ponto importante aqui é que independente de qualquer coisa eu não quero que você economize com tokens para você explorar, para você gerar documento, para você processar informação, principalmente em um workflow de desenvolvimento. Agora, no próximo vídeo, a gente vai falar do outro lado da moeda e esse outro lado realmente é muito importante. Então vamos nessa.